{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPNuSjFwwiczfm2Guj0OK9K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Calcifer777/learn-deep-learning/blob/main/generative-models/samples/WGAN_PL_f.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "pip install -q torchinfo"
      ],
      "metadata": {
        "id": "T4nOx27uBlRg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!test -e samples/ || mkdir samples\n",
        "!test -d \"./samples/\" || rm ./samples/*"
      ],
      "metadata": {
        "id": "yHghV7kg7qdn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RmcP3mxD6NOU"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "from torch.nn.functional import mse_loss\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms.v2.functional as F\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.transforms import (\n",
        "    Compose,\n",
        "    PILToTensor,\n",
        ")\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "D3KzKiao6VeM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "else:\n",
        "    device = \"cpu\""
      ],
      "metadata": {
        "id": "FWYdS43pctke"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters"
      ],
      "metadata": {
        "id": "jkq61Kfn6id9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 15\n",
        "BATCH_SIZE = 64\n",
        "LATENT_DIM = 100\n",
        "BASE_DIM_GEN = 7\n",
        "BASE_GEN_CH = 256\n",
        "CRITIC_TO_GEN_UPDATES = 3\n",
        "GP_WEIGHT = 10.0\n",
        "PATH_SAMPLES = Path(\"./samples/\")\n",
        "\n",
        "LR_G = 1e-4\n",
        "LR_C = 1e-4"
      ],
      "metadata": {
        "id": "bzqxHT2T6epp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_SAMPLES.mkdir(exist_ok=True)"
      ],
      "metadata": {
        "id": "BUiQ3W6LwNpy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "-ihvQFk79gAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(img):\n",
        "    img = F.pil_to_tensor(img)\n",
        "    img = (img - 127.5) / 127.5\n",
        "    return img"
      ],
      "metadata": {
        "id": "685Iz2AbHd6t"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train = datasets.FashionMNIST(\n",
        "    \"./data/fashion-mnist/\",\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=transform,\n",
        ")"
      ],
      "metadata": {
        "id": "Tny1kc9l9iZq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dl_train = DataLoader(\n",
        "    dataset=ds_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        ")"
      ],
      "metadata": {
        "id": "Z8OUWLgECHSt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_batch = next(iter(dl_train))\n",
        "sample_batch[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvmlbk7GEYZ0",
        "outputId": "ffeb4b1d-0ace-43ae-93e9-ddf6b5b85c69"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "O0lRCk0t6dh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Critic(nn.Module):\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(Critic, self).__init__(*args, **kwargs)\n",
        "        self.net = nn.Sequential(\n",
        "            self.conv_block(1, 64, activation=True),\n",
        "            self.conv_block(64, 128, activation=True),\n",
        "            nn.Conv2d(128, 1, kernel_size=(5, 5)),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def conv_block(in_ch: int, out_ch: int, activation: bool, kernel_size=4) -> Tensor:\n",
        "        layers = [\n",
        "            nn.Conv2d(in_ch, out_ch, kernel_size=4, stride=2, padding=\"valid\"),\n",
        "        ]\n",
        "        if activation:\n",
        "            layers.append(nn.LeakyReLU(0.2))\n",
        "            layers.append(nn.Dropout(0.2))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "    def forward(self, x: Tensor):\n",
        "        x = self.net(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "r9eBg8Pz6hA6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand((2, 1, 28, 28))\n",
        "summary(Critic(), input_data=(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwBA0IJeNGSi",
        "outputId": "7bc862dd-b432-4369-db8f-30d0ca9c2cfd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Critic                                   [2, 1]                    --\n",
              "├─Sequential: 1-1                        [2, 1]                    --\n",
              "│    └─Sequential: 2-1                   [2, 64, 13, 13]           --\n",
              "│    │    └─Conv2d: 3-1                  [2, 64, 13, 13]           1,088\n",
              "│    │    └─LeakyReLU: 3-2               [2, 64, 13, 13]           --\n",
              "│    │    └─Dropout: 3-3                 [2, 64, 13, 13]           --\n",
              "│    └─Sequential: 2-2                   [2, 128, 5, 5]            --\n",
              "│    │    └─Conv2d: 3-4                  [2, 128, 5, 5]            131,200\n",
              "│    │    └─LeakyReLU: 3-5               [2, 128, 5, 5]            --\n",
              "│    │    └─Dropout: 3-6                 [2, 128, 5, 5]            --\n",
              "│    └─Conv2d: 2-3                       [2, 1, 1, 1]              3,201\n",
              "│    └─Flatten: 2-4                      [2, 1]                    --\n",
              "==========================================================================================\n",
              "Total params: 135,489\n",
              "Trainable params: 135,489\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 6.93\n",
              "==========================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 0.22\n",
              "Params size (MB): 0.54\n",
              "Estimated Total Size (MB): 0.77\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(Generator, self).__init__(*args, **kwargs)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(LATENT_DIM, BASE_DIM_GEN * BASE_DIM_GEN * BASE_GEN_CH),\n",
        "            nn.ReLU(0.2),\n",
        "            nn.Unflatten(-1, (BASE_GEN_CH, BASE_DIM_GEN, BASE_DIM_GEN)),\n",
        "            self.conv_block(BASE_GEN_CH, BASE_GEN_CH // 2, True, True),\n",
        "            self.conv_block(BASE_GEN_CH // 2, 1, False, False),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def conv_block(\n",
        "        in_ch: int,\n",
        "        out_ch: int,\n",
        "        batch_norm: bool,\n",
        "        activation: bool,\n",
        "    ):\n",
        "        # Base\n",
        "        layers = [\n",
        "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=\"same\"),\n",
        "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "        ]\n",
        "        if batch_norm:\n",
        "            layers.append(nn.BatchNorm2d(out_ch))\n",
        "        if activation:\n",
        "            layers.append(nn.ReLU())\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x: Tensor):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "pHiXS1zMRB1L"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.rand((2, 100))\n",
        "summary(Generator(), input_data=z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "561xdn2wTJl7",
        "outputId": "863491af-c9fa-49ee-c3aa-9bcb48b51836"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Generator                                [2, 1, 28, 28]            --\n",
              "├─Sequential: 1-1                        [2, 1, 28, 28]            --\n",
              "│    └─Linear: 2-1                       [2, 12544]                1,266,944\n",
              "│    └─ReLU: 2-2                         [2, 12544]                --\n",
              "│    └─Unflatten: 2-3                    [2, 256, 7, 7]            --\n",
              "│    └─Sequential: 2-4                   [2, 128, 14, 14]          --\n",
              "│    │    └─Conv2d: 3-1                  [2, 128, 7, 7]            295,040\n",
              "│    │    └─Upsample: 3-2                [2, 128, 14, 14]          --\n",
              "│    │    └─BatchNorm2d: 3-3             [2, 128, 14, 14]          256\n",
              "│    │    └─ReLU: 3-4                    [2, 128, 14, 14]          --\n",
              "│    └─Sequential: 2-5                   [2, 1, 28, 28]            --\n",
              "│    │    └─Conv2d: 3-5                  [2, 1, 14, 14]            1,153\n",
              "│    │    └─Upsample: 3-6                [2, 1, 28, 28]            --\n",
              "│    └─Tanh: 2-6                         [2, 1, 28, 28]            --\n",
              "==========================================================================================\n",
              "Total params: 1,563,393\n",
              "Trainable params: 1,563,393\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 31.90\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.71\n",
              "Params size (MB): 6.25\n",
              "Estimated Total Size (MB): 6.96\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "5CRpT5AIccHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator().to(device)\n",
        "critic = Critic().to(device)\n",
        "\n",
        "opt_g = torch.optim.Adam(generator.parameters(), LR_G)\n",
        "opt_c = torch.optim.Adam(critic.parameters(), LR_C)"
      ],
      "metadata": {
        "id": "cYS8Lo9JcbyB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_penalty(batch: Tensor, img_gen: Tensor) -> Tensor:\n",
        "    interp_w = torch.rand((batch.shape[0], 1, 1, 1)).to(device)\n",
        "    interp = interp_w * batch + (1-interp_w) * img_gen\n",
        "    scores = critic(interp)\n",
        "    norm = scores.norm(2, dim=-1)\n",
        "    gp = mse_loss(norm, torch.ones_like(norm))\n",
        "    return gp"
      ],
      "metadata": {
        "id": "NYaPi631ijpj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step_c(batch):\n",
        "    opt_c.zero_grad()\n",
        "    z = torch.rand((batch.shape[0], LATENT_DIM)).to(device)\n",
        "    img_gen = generator(z).detach()\n",
        "    score_real = critic(batch)\n",
        "    score_gen = critic(img_gen)\n",
        "    loss_w = score_gen.mean() - score_real.mean()\n",
        "    loss_gp = gradient_penalty(batch, img_gen)\n",
        "    loss = loss_w + GP_WEIGHT * loss_gp\n",
        "    loss.backward()\n",
        "    opt_c.step()\n",
        "    return dict(\n",
        "        loss_c=loss.item(),\n",
        "        loss_c_w=loss_w.item(),\n",
        "        loss_c_gp=loss_gp.item(),\n",
        "    )"
      ],
      "metadata": {
        "id": "ukT6vAZ6dCpk"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step_g(batch):\n",
        "    opt_g.zero_grad()\n",
        "    z = torch.rand((batch.shape[0], LATENT_DIM)).to(device)\n",
        "    img_gen = generator(z)\n",
        "    score = critic(img_gen)\n",
        "    loss = - score.mean()\n",
        "    loss.backward()\n",
        "    opt_g.step()\n",
        "    return dict(\n",
        "        loss_g=loss.item(),\n",
        "    )"
      ],
      "metadata": {
        "id": "1alghb2xTffU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "def live_plot(metrics: List[dict], title=''):\n",
        "    \"\"\"\n",
        "    0. List[Dict[str, float]]\n",
        "    1. pd.DataFrame\n",
        "    2. Column-wise running mean\n",
        "    3. Dict[str, List[float]]\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame.from_records(metrics).expanding().mean()\n",
        "    data_dict = df.to_dict(orient=\"list\")\n",
        "    #\n",
        "    clear_output(wait=True)\n",
        "    fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
        "    for ax, (k, v) in zip(axes.flatten(), data_dict.items()):\n",
        "        ax.plot(v)\n",
        "        ax.set_title(k)\n",
        "    plt.grid(False)\n",
        "    plt.show();"
      ],
      "metadata": {
        "id": "w77mRIYum6q0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.inference_mode()\n",
        "def generate_samples(fname):\n",
        "    generator.eval()\n",
        "    z = torch.rand((9, 100)).to(device)\n",
        "    x = generator(z)\n",
        "    grid = make_grid(x, nrow=3)\n",
        "    img = F.to_pil_image(grid)\n",
        "    img.save(PATH_SAMPLES / (fname + \".png\"))"
      ],
      "metadata": {
        "id": "qwE5-cw5uO12"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(epoch_id: int, history: List[dict]):\n",
        "    pbar = tqdm(enumerate(dl_train, start=1), total=len(dl_train))\n",
        "    for i, (batch, _) in pbar:\n",
        "        generator.train()\n",
        "        critic.train()\n",
        "        batch = batch.to(device)\n",
        "        for j in range(CRITIC_TO_GEN_UPDATES):\n",
        "            loss_d = train_step_c(batch)\n",
        "        loss_g = train_step_g(batch)\n",
        "        metrics = {**loss_d, **loss_g}\n",
        "        history.append(metrics)\n",
        "        if i % 250 == 0:\n",
        "            live_plot(history)\n",
        "            generate_samples(f\"e{epoch_id:03d}_{i:04d}\")\n",
        "    return history"
      ],
      "metadata": {
        "id": "_Q-mER_udGAH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = []\n",
        "\n",
        "for epoch_id in range(EPOCHS):\n",
        "    history = train_epoch(epoch_id, history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3RXSWi_s3Kh",
        "outputId": "24203b8e-1a92-47de-a130-c2e4adb72e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 176/938 [00:10<01:16,  9.95it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame([[1,3], [2,6], [3,9]]).expanding().mean()"
      ],
      "metadata": {
        "id": "2sCmiZqZrIh6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}