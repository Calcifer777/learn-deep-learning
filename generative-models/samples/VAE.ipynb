{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6k/YiBPgSyzAOP3gnirn4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Calcifer777/learn-deep-learning/blob/main/generative-models/samples/VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnmu7MODk9it"
      },
      "outputs": [],
      "source": [
        "from typing import Optional, Tuple\n",
        "from enum import Enum\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constants"
      ],
      "metadata": {
        "id": "QjUjzqLAKMxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PI = torch.from_numpy(np.asarray(np.pi))\n",
        "EPS = 1.e-5"
      ],
      "metadata": {
        "id": "PqLjZKc70gR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "M--dvxLMKJas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_normal(x: Tensor, mu: Tensor, logvar: int) -> Tensor:\n",
        "    dim = mu.shape[0]\n",
        "    return (\n",
        "        - 0.5 * dim * torch.log(2 * PI)\n",
        "        - 0.5 * logvar\n",
        "        - 0.5 * (x-mu)**2 * torch.exp(-logvar)\n",
        "    )"
      ],
      "metadata": {
        "id": "rgMHThQXArGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_categorical(x, p, num_classes=256, reduction=None, dim=None):\n",
        "    x_one_hot = F.one_hot(x.long(), num_classes=num_classes)\n",
        "    log_p = x_one_hot * torch.log(torch.clamp(p, EPS, 1. - EPS))\n",
        "    if reduction == 'avg':\n",
        "        return torch.mean(log_p, dim)\n",
        "    elif reduction == 'sum':\n",
        "        return torch.sum(log_p, dim)\n",
        "    else:\n",
        "        return log_p"
      ],
      "metadata": {
        "id": "AGrz18flDtCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VAE"
      ],
      "metadata": {
        "id": "M9GUL5GoKTj2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "trdAwFn9RyRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncodingType(str, Enum):\n",
        "    encode = \"encode\"\n",
        "    sample = \"sample\""
      ],
      "metadata": {
        "id": "SKQ9FoU_v6dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, net: nn.Module):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.net = net\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x: Optional[Tensor],\n",
        "    ) -> Tuple[Tensor, Tensor]:\n",
        "        mu, logvar = self.encode(x)\n",
        "        out = self.reparametrize(mu, logvar)\n",
        "        return out, self.log_prob(out, mu, logvar)\n",
        "\n",
        "    def sample(self, mu_logvar: Tuple[Tensor, Tensor]):\n",
        "        mu, logvar = mu_logvar\n",
        "        x = self.reparametrize(mu, logvar)\n",
        "        return x, self.log_prob(x, mu, logvar)\n",
        "\n",
        "    @staticmethod\n",
        "    def log_prob(x: Tensor, mu: Tensor, logvar: Tensor) -> Tensor:\n",
        "        return log_normal(x, mu, logvar)\n",
        "\n",
        "    def encode(self, x: Tensor) -> Tuple[Tensor, Tensor]:\n",
        "        x = nn.Flatten()(x)\n",
        "        x = self.net(x)\n",
        "        mu, log_var = torch.chunk(x, 2, dim=-1)\n",
        "        return mu, log_var\n",
        "\n",
        "    @staticmethod\n",
        "    def reparametrize(mu: Tensor, logvar: Tensor) -> Tensor:\n",
        "        sigma = torch.exp(0.5*logvar)\n",
        "        eps = torch.rand_like(sigma)\n",
        "        return mu + sigma * eps\n"
      ],
      "metadata": {
        "id": "4Wwc7a60lBOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder"
      ],
      "metadata": {
        "id": "QS2L6YrPUEQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, net: nn.Module, num_classes: int):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.net = net\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        logits = self.net(x)\n",
        "        logits = logits.view(\n",
        "            logits.shape[0],  #batch_size\n",
        "            -1,\n",
        "            self.num_classes,\n",
        "        )\n",
        "        probs = torch.softmax(logits, -1)\n",
        "        return probs\n",
        "\n",
        "    def sample(self, x: Tensor) -> Tensor:\n",
        "        probs = self.forward(x)\n",
        "        sampled = torch.multinomial(\n",
        "            input=probs.view(-1, self.num_classes),  # prob dist must be 1 or 2 dims\n",
        "            num_samples=1\n",
        "        ).view(probs.shape[0], probs.shape[1])\n",
        "        return sampled\n",
        "\n",
        "    def log_prob(self, x, mu):\n",
        "        return log_categorical(\n",
        "            x,\n",
        "            mu,\n",
        "            num_classes=self.num_classes,\n",
        "            reduction =\"sum\",\n",
        "            dim=-1,\n",
        "        ).sum(-1)"
      ],
      "metadata": {
        "id": "_gICUflB3su9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Prior(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super(Prior, self).__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def sample(self, batch_size) -> Tensor:\n",
        "        return torch.randn((batch_size, self.dim))\n",
        "\n",
        "    def log_prob(self, x: Tensor):\n",
        "        return log_normal(x, torch.zeros_like(x), torch.ones_like(x))"
      ],
      "metadata": {
        "id": "g5dENgCl_kvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VAE"
      ],
      "metadata": {
        "id": "qY1JSxJkUANr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReductionType(str, Enum):\n",
        "    mean = \"mean\"\n",
        "    sum = \"sum\""
      ],
      "metadata": {
        "id": "DhumfGaKa9SY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        encoder_net: nn.Module,\n",
        "        decoder_net: nn.Module,\n",
        "        prior: Prior,\n",
        "        num_classes: int,\n",
        "    ):\n",
        "        super(VAE, self).__init__()\n",
        "        self.encoder = Encoder(encoder_net)\n",
        "        self.decoder = Decoder(decoder_net, num_classes)\n",
        "        self.prior = prior\n",
        "\n",
        "    def forward(self, x: Tensor, reduction: ReductionType = ReductionType.mean):\n",
        "        z, log_prob_enc = self.encoder(x)\n",
        "        decoded = self.decoder(z)\n",
        "        rec_error = self.decoder.log_prob(x, decoded)\n",
        "        kl = (\n",
        "            self.prior.log_prob(z) - log_prob_enc\n",
        "        ).sum(-1)\n",
        "        elbo = - (rec_error + kl)\n",
        "        if reduction == ReductionType.mean:\n",
        "            out = elbo.mean()\n",
        "        elif reduction == ReductionType.sum:\n",
        "            out = elbo.sum()\n",
        "        return out\n",
        "\n",
        "    def sample(self, batch_size: int):\n",
        "        z = self.prior.sample(batch_size)\n",
        "        return self.decoder.sample(z)"
      ],
      "metadata": {
        "id": "Ju-FSRIb9Z41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "e8UfweYNaUkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "size_img = 64\n",
        "size_z = 8\n",
        "size_h = 16\n",
        "num_classes = 17"
      ],
      "metadata": {
        "id": "zEWPVv3_p-7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_net = nn.Sequential(\n",
        "    nn.Linear(size_img, size_h),\n",
        "    nn.LeakyReLU(),\n",
        "    nn.Linear(size_h, size_h),\n",
        "    nn.LeakyReLU(),\n",
        "    nn.Linear(size_h, 2*size_z),  # output concatenated mu and sigma\n",
        ")\n",
        "\n",
        "decoder_net = nn.Sequential(\n",
        "    nn.Linear(size_z, size_h),\n",
        "    nn.LeakyReLU(),\n",
        "    nn.Linear(size_h, size_h),\n",
        "    nn.LeakyReLU(),\n",
        "    nn.Linear(size_h, size_img*num_classes),\n",
        ")"
      ],
      "metadata": {
        "id": "6X6eDVm9pWPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(encoder_net)"
      ],
      "metadata": {
        "id": "yB8IgLQBq16x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prior = Prior(dim=size_z)"
      ],
      "metadata": {
        "id": "X0WRKLhVK1QU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = torch.rand(size=(4, size_img))\n",
        "img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tv3l66-Yq6oj",
        "outputId": "b4ad8942-d54f-494d-e564-68bedda88029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z, log_prob = encoder(img)"
      ],
      "metadata": {
        "id": "Swh_RQ8BsK-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder(decoder_net, num_classes)"
      ],
      "metadata": {
        "id": "xetwthKLxRf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded = decoder(z)\n",
        "print(decoded.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IL8iZq535NwU",
        "outputId": "631d797a-364a-44ef-f239-6827a9825f3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 64, 17])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vae = VAE(encoder_net, decoder_net, prior, num_classes)"
      ],
      "metadata": {
        "id": "xb_Vn6-XKhQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9My7wlHLHj4",
        "outputId": "6c9d3175-a82c-4c78-876b-d99b01f37325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(187.2825, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vae.sample(2).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWYTYGUWcr9M",
        "outputId": "57492ebd-afda-4b26-c5f1-608e5656f323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vae.decoder.sample(vae.prior.sample(2)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqEHaVX1cwcI",
        "outputId": "6b1a33f5-91d4-412a-ccfb-a1a2422c55db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "WPWhx-3LJ2yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn import datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from matplotlib import pyplot as plt\n",
        "import PIL"
      ],
      "metadata": {
        "id": "TOeYGB5b6Xrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Digits(Dataset):\n",
        "    \"\"\"Scikit-Learn Digits dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, mode='train', transforms=None):\n",
        "        digits = load_digits()\n",
        "        if mode == 'train':\n",
        "            self.data = digits.data[:1000].astype(np.float32)\n",
        "        elif mode == 'val':\n",
        "            self.data = digits.data[1000:1350].astype(np.float32)\n",
        "        else:\n",
        "            self.data = digits.data[1350:].astype(np.float32)\n",
        "\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        if self.transforms:\n",
        "            sample = self.transforms(sample)\n",
        "        return sample"
      ],
      "metadata": {
        "id": "SQY3WuPM6coE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = Digits(mode='train')\n",
        "val_data = Digits(mode='val')\n",
        "test_data = Digits(mode='test')\n",
        "\n",
        "training_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "n5SEV0N06Q1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.random.randint(len(train_data))\n",
        "plt.imshow(train_data[idx].reshape(8, 8), interpolation='nearest')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "6n7QSPoI6e6H",
        "outputId": "68bfd364-b7ef-4bcc-d777-295afc461e43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "DgXQn5n3O9oZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(test_loader, name=None, model_best=None, epoch=None):\n",
        "    # EVALUATION\n",
        "    if model_best is None:\n",
        "        # load best performing model\n",
        "        model_best = torch.load(name + '.model')\n",
        "\n",
        "    model_best.eval()\n",
        "    loss = 0.\n",
        "    N = 0.\n",
        "    for indx_batch, test_batch in enumerate(test_loader):\n",
        "        loss_t = model_best.forward(test_batch, reduction='sum')\n",
        "        loss = loss + loss_t.item()\n",
        "        N = N + test_batch.shape[0]\n",
        "    loss = loss / N\n",
        "\n",
        "    if epoch is None:\n",
        "        print(f'FINAL LOSS: nll={loss}')\n",
        "    else:\n",
        "        print(f'Epoch: {epoch}, val nll={loss}')\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "jN77SjLFP5zQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def samples_real(name, test_loader):\n",
        "    # REAL-------\n",
        "    num_x = 4\n",
        "    num_y = 4\n",
        "    x = next(iter(test_loader)).detach().numpy()\n",
        "\n",
        "    fig, ax = plt.subplots(num_x, num_y)\n",
        "    for i, ax in enumerate(ax.flatten()):\n",
        "        plottable_image = np.reshape(x[i], (8, 8))\n",
        "        ax.imshow(plottable_image, cmap='gray')\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.savefig(name+'_real_images.png', bbox_inches='tight')\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "g1vtSq72P8Q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def samples_generated(name, data_loader, extra_name=''):\n",
        "    x = next(iter(data_loader)).detach().numpy()\n",
        "\n",
        "    # GENERATIONS-------\n",
        "    model_best = torch.load(name + '.model')\n",
        "    model_best.eval()\n",
        "\n",
        "    num_x = 4\n",
        "    num_y = 4\n",
        "    x = model_best.sample(num_x * num_y)\n",
        "    x = x.detach().numpy()\n",
        "\n",
        "    fig, ax = plt.subplots(num_x, num_y)\n",
        "    for i, ax in enumerate(ax.flatten()):\n",
        "        plottable_image = np.reshape(x[i], (8, 8))\n",
        "        ax.imshow(plottable_image, cmap='gray')\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.savefig(name + '_generated_images' + extra_name + '.png', bbox_inches='tight')\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "APWC6ppOPL44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training(name, max_patience, num_epochs, model, optimizer, training_loader, val_loader):\n",
        "    nll_val = []\n",
        "    best_nll = 1000.\n",
        "    patience = 0\n",
        "\n",
        "    # Main loop\n",
        "    for e in range(num_epochs):\n",
        "        # TRAINING\n",
        "        model.train()\n",
        "        for indx_batch, batch in enumerate(training_loader):\n",
        "            if hasattr(model, 'dequantization'):\n",
        "                if model.dequantization:\n",
        "                    batch = batch + torch.rand(batch.shape)\n",
        "            loss = model(batch)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward(retain_graph=True)\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        loss_val = evaluation(val_loader, model_best=model, epoch=e)\n",
        "        nll_val.append(loss_val)  # save for plotting\n",
        "\n",
        "        if e == 0:\n",
        "            print('saved!')\n",
        "            torch.save(model, name + '.model')\n",
        "            best_nll = loss_val\n",
        "        else:\n",
        "            if loss_val < best_nll:\n",
        "                print('saved!')\n",
        "                torch.save(model, name + '.model')\n",
        "                best_nll = loss_val\n",
        "                patience = 0\n",
        "\n",
        "                samples_generated(name, val_loader, extra_name=\"_epoch_\" + str(e))\n",
        "            else:\n",
        "                patience = patience + 1\n",
        "\n",
        "        if patience > max_patience:\n",
        "            break\n",
        "\n",
        "    nll_val = np.asarray(nll_val)\n",
        "\n",
        "    return nll_val"
      ],
      "metadata": {
        "id": "QOWiyrjaPzDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_curve(name, nll_val):\n",
        "    plt.plot(np.arange(len(nll_val)), nll_val, linewidth='3')\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('nll')\n",
        "    plt.savefig(name + '_nll_val_curve.png', bbox_inches='tight')\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "XOFRM3wwP1lN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run"
      ],
      "metadata": {
        "id": "5afYxdWcPMdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "ymjJstLdPWKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size_img = 64   # input dimension\n",
        "size_h = 256  # the number of neurons in scale (s) and translation (t) nets\n",
        "size_z = 16  # number of latents\n",
        "num_classes = 17\n",
        "\n",
        "lr = 1e-3 # learning rate\n",
        "num_epochs = 1000 # max. number of epochs\n",
        "max_patience = 20 # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped"
      ],
      "metadata": {
        "id": "gEApIrvLPQPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_dir = 'results/'\n",
        "if not(os.path.exists(result_dir)):\n",
        "    os.mkdir(result_dir)\n",
        "name = 'vae'"
      ],
      "metadata": {
        "id": "kzVg8XWrPUlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_net = nn.Sequential(\n",
        "    nn.Linear(size_img, size_h),\n",
        "    nn.LeakyReLU(),\n",
        "    nn.Linear(size_h, size_h),\n",
        "    nn.LeakyReLU(),\n",
        "    nn.Linear(size_h, 2*size_z),  # output concatenated mu and sigma\n",
        ")\n",
        "\n",
        "decoder_net = nn.Sequential(\n",
        "    nn.Linear(size_z, size_h),\n",
        "    nn.LeakyReLU(),\n",
        "    nn.Linear(size_h, size_h),\n",
        "    nn.LeakyReLU(),\n",
        "    nn.Linear(size_h, size_img*num_classes),\n",
        ")"
      ],
      "metadata": {
        "id": "doWMQFrPSGoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VAE(\n",
        "    encoder_net=encoder_net,\n",
        "    decoder_net=decoder_net,\n",
        "    prior=Prior(dim=size_z),\n",
        "    num_classes=num_classes,\n",
        ")"
      ],
      "metadata": {
        "id": "rpDYr6BKPi0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTIMIZER\n",
        "optimizer = torch.optim.Adamax([p for p in model.parameters() if p.requires_grad == True], lr=lr)\n",
        "\n",
        "# Training procedure\n",
        "nll_val = training(\n",
        "    name=result_dir + name,\n",
        "    max_patience=max_patience,\n",
        "    num_epochs=num_epochs,\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    training_loader=training_loader,\n",
        "    val_loader=val_loader,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EYlxeE5O84x",
        "outputId": "4b02c35c-8059-4098-b01d-76032d4466c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, val nll=109.27550920758928\n",
            "saved!\n",
            "Epoch: 1, val nll=99.90139369419643\n",
            "saved!\n",
            "Epoch: 2, val nll=98.78867606026786\n",
            "saved!\n",
            "Epoch: 3, val nll=97.83171037946428\n",
            "saved!\n",
            "Epoch: 4, val nll=97.93759347098214\n",
            "Epoch: 5, val nll=97.26201102120535\n",
            "saved!\n",
            "Epoch: 6, val nll=96.99905064174108\n",
            "saved!\n",
            "Epoch: 7, val nll=96.41723702566965\n",
            "saved!\n",
            "Epoch: 8, val nll=95.92390276227678\n",
            "saved!\n",
            "Epoch: 9, val nll=95.50353934151785\n",
            "saved!\n",
            "Epoch: 10, val nll=94.96653041294643\n",
            "saved!\n",
            "Epoch: 11, val nll=94.36927943638393\n",
            "saved!\n",
            "Epoch: 12, val nll=94.41122349330357\n",
            "Epoch: 13, val nll=93.929443359375\n",
            "saved!\n",
            "Epoch: 14, val nll=93.7358203125\n",
            "saved!\n",
            "Epoch: 15, val nll=93.88160714285715\n",
            "Epoch: 16, val nll=93.17721958705357\n",
            "saved!\n",
            "Epoch: 17, val nll=93.07366908482143\n",
            "saved!\n",
            "Epoch: 18, val nll=92.54508440290178\n",
            "saved!\n",
            "Epoch: 19, val nll=92.40188058035714\n",
            "saved!\n",
            "Epoch: 20, val nll=92.1022021484375\n",
            "saved!\n",
            "Epoch: 21, val nll=91.95657645089285\n",
            "saved!\n",
            "Epoch: 22, val nll=91.39445521763393\n",
            "saved!\n",
            "Epoch: 23, val nll=90.94871442522322\n",
            "saved!\n",
            "Epoch: 24, val nll=91.0632373046875\n",
            "Epoch: 25, val nll=90.769892578125\n",
            "saved!\n",
            "Epoch: 26, val nll=90.402119140625\n",
            "saved!\n",
            "Epoch: 27, val nll=91.00887276785714\n",
            "Epoch: 28, val nll=90.24173130580357\n",
            "saved!\n",
            "Epoch: 29, val nll=89.91894670758928\n",
            "saved!\n",
            "Epoch: 30, val nll=90.27681640625\n",
            "Epoch: 31, val nll=89.58947893415178\n",
            "saved!\n",
            "Epoch: 32, val nll=89.66624372209822\n",
            "Epoch: 33, val nll=89.24722865513392\n",
            "saved!\n",
            "Epoch: 34, val nll=89.3148974609375\n",
            "Epoch: 35, val nll=89.40256138392857\n",
            "Epoch: 36, val nll=89.11734654017857\n",
            "saved!\n",
            "Epoch: 37, val nll=89.25740513392857\n",
            "Epoch: 38, val nll=89.01911481584821\n",
            "saved!\n",
            "Epoch: 39, val nll=88.65544154575893\n",
            "saved!\n",
            "Epoch: 40, val nll=89.06428850446429\n",
            "Epoch: 41, val nll=89.18190011160715\n",
            "Epoch: 42, val nll=88.50732840401785\n",
            "saved!\n",
            "Epoch: 43, val nll=88.180087890625\n",
            "saved!\n",
            "Epoch: 44, val nll=88.67793875558036\n",
            "Epoch: 45, val nll=88.24988699776786\n",
            "Epoch: 46, val nll=88.60207798549108\n",
            "Epoch: 47, val nll=88.27312430245536\n",
            "Epoch: 48, val nll=87.94855189732142\n",
            "saved!\n",
            "Epoch: 49, val nll=88.30224051339286\n",
            "Epoch: 50, val nll=88.08897600446429\n",
            "Epoch: 51, val nll=88.37089704241072\n",
            "Epoch: 52, val nll=88.17189453125\n",
            "Epoch: 53, val nll=87.825654296875\n",
            "saved!\n",
            "Epoch: 54, val nll=87.76951171875\n",
            "saved!\n",
            "Epoch: 55, val nll=87.44489536830358\n",
            "saved!\n",
            "Epoch: 56, val nll=87.53940359933036\n",
            "Epoch: 57, val nll=87.20197893415178\n",
            "saved!\n",
            "Epoch: 58, val nll=87.77542131696428\n",
            "Epoch: 59, val nll=87.48364397321428\n",
            "Epoch: 60, val nll=87.62159388950893\n",
            "Epoch: 61, val nll=87.76121930803572\n",
            "Epoch: 62, val nll=87.50306291852678\n",
            "Epoch: 63, val nll=87.354736328125\n",
            "Epoch: 64, val nll=87.6273828125\n",
            "Epoch: 65, val nll=87.15965890066964\n",
            "saved!\n",
            "Epoch: 66, val nll=87.35861118861607\n",
            "Epoch: 67, val nll=87.2013720703125\n",
            "Epoch: 68, val nll=86.87899693080357\n",
            "saved!\n",
            "Epoch: 69, val nll=86.84997209821428\n",
            "saved!\n",
            "Epoch: 70, val nll=86.6359912109375\n",
            "saved!\n",
            "Epoch: 71, val nll=86.92863978794642\n",
            "Epoch: 72, val nll=86.94164411272321\n",
            "Epoch: 73, val nll=87.07472307477678\n",
            "Epoch: 74, val nll=87.00446568080358\n",
            "Epoch: 75, val nll=86.92086635044643\n",
            "Epoch: 76, val nll=87.14632742745536\n",
            "Epoch: 77, val nll=86.89787876674107\n",
            "Epoch: 78, val nll=87.03111188616072\n",
            "Epoch: 79, val nll=87.23779715401785\n",
            "Epoch: 80, val nll=86.89754952566965\n",
            "Epoch: 81, val nll=86.90948521205357\n",
            "Epoch: 82, val nll=86.69538853236607\n",
            "Epoch: 83, val nll=86.60222935267858\n",
            "saved!\n",
            "Epoch: 84, val nll=86.61316755022321\n",
            "Epoch: 85, val nll=86.98402204241071\n",
            "Epoch: 86, val nll=86.82807756696428\n",
            "Epoch: 87, val nll=87.08956194196429\n",
            "Epoch: 88, val nll=86.71392438616071\n",
            "Epoch: 89, val nll=87.18957868303572\n",
            "Epoch: 90, val nll=86.46031877790179\n",
            "saved!\n",
            "Epoch: 91, val nll=86.76729771205358\n",
            "Epoch: 92, val nll=86.26462541852679\n",
            "saved!\n",
            "Epoch: 93, val nll=87.12690987723214\n",
            "Epoch: 94, val nll=86.94938895089285\n",
            "Epoch: 95, val nll=86.56000069754464\n",
            "Epoch: 96, val nll=87.45761858258929\n",
            "Epoch: 97, val nll=86.92723911830358\n",
            "Epoch: 98, val nll=87.1487158203125\n",
            "Epoch: 99, val nll=86.96381068638392\n",
            "Epoch: 100, val nll=87.52205984933036\n",
            "Epoch: 101, val nll=86.57930733816964\n",
            "Epoch: 102, val nll=87.20378976004464\n",
            "Epoch: 103, val nll=86.81645647321429\n",
            "Epoch: 104, val nll=87.10545200892857\n",
            "Epoch: 105, val nll=87.40134695870536\n",
            "Epoch: 106, val nll=87.177255859375\n",
            "Epoch: 107, val nll=87.67782087053571\n",
            "Epoch: 108, val nll=86.94235560825892\n",
            "Epoch: 109, val nll=87.426220703125\n",
            "Epoch: 110, val nll=87.37989606584821\n",
            "Epoch: 111, val nll=87.68043038504464\n",
            "Epoch: 112, val nll=87.41499581473214\n",
            "Epoch: 113, val nll=87.50586286272322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = evaluation(name=result_dir + name, test_loader=test_loader)\n",
        "with open(result_dir + name + '_test_loss.txt', \"w\") as fp:\n",
        "    fp.write(str(test_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plv4Ns2fd4g9",
        "outputId": "2a93e178-6acd-4595-da19-a4e956d9b664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINAL LOSS: nll=82.78310262863535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples_real(result_dir + name, test_loader)"
      ],
      "metadata": {
        "id": "4iMkZJrud58m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_curve(result_dir + name, nll_val)"
      ],
      "metadata": {
        "id": "J4a5dr1Sdz81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "# rm  results/*\n",
        "test -e vae_example.ipynb | wget https://raw.githubusercontent.com/jmtomczak/intro_dgm/main/vaes/vae_example.ipynb\n",
        "test -e vae_example.py | jupyter nbconvert --to python vae_example.ipynb\n",
        "pip install pytorch_model_summary\n",
        "python vae_example.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgygJMxBfFTV",
        "outputId": "00a65eed-3562-4669-8fca-637ee599259c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch_model_summary in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch_model_summary) (4.66.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pytorch_model_summary) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch_model_summary) (1.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_model_summary) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_model_summary) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_model_summary) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_model_summary) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_model_summary) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_model_summary) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_model_summary) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pytorch_model_summary) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pytorch_model_summary) (1.3.0)\n",
            "VAE by JT.\n",
            "ENCODER:\n",
            " -----------------------------------------------------------------------\n",
            "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
            "=======================================================================\n",
            "          Linear-1            [1, 256]          16,640          16,640\n",
            "       LeakyReLU-2            [1, 256]               0               0\n",
            "          Linear-3            [1, 256]          65,792          65,792\n",
            "       LeakyReLU-4            [1, 256]               0               0\n",
            "          Linear-5             [1, 32]           8,224           8,224\n",
            "=======================================================================\n",
            "Total params: 90,656\n",
            "Trainable params: 90,656\n",
            "Non-trainable params: 0\n",
            "-----------------------------------------------------------------------\n",
            "\n",
            "DECODER:\n",
            " -----------------------------------------------------------------------\n",
            "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
            "=======================================================================\n",
            "          Linear-1            [1, 256]           4,352           4,352\n",
            "       LeakyReLU-2            [1, 256]               0               0\n",
            "          Linear-3            [1, 256]          65,792          65,792\n",
            "       LeakyReLU-4            [1, 256]               0               0\n",
            "          Linear-5           [1, 1088]         279,616         279,616\n",
            "=======================================================================\n",
            "Total params: 349,760\n",
            "Trainable params: 349,760\n",
            "Non-trainable params: 0\n",
            "-----------------------------------------------------------------------\n",
            "Epoch: 0, val nll=123.84826032366071\n",
            "saved!\n",
            "Epoch: 1, val nll=113.32648716517858\n",
            "saved!\n",
            "Epoch: 2, val nll=112.23661063058036\n",
            "saved!\n",
            "Epoch: 3, val nll=111.7949072265625\n",
            "saved!\n",
            "Epoch: 4, val nll=111.66184500558036\n",
            "saved!\n",
            "Epoch: 5, val nll=111.46729422433036\n",
            "saved!\n",
            "Epoch: 6, val nll=111.56524204799108\n",
            "Epoch: 7, val nll=111.38138741629464\n",
            "saved!\n",
            "Epoch: 8, val nll=111.37368303571428\n",
            "saved!\n",
            "Epoch: 9, val nll=111.15663364955357\n",
            "saved!\n",
            "Epoch: 10, val nll=111.27090890066964\n",
            "Epoch: 11, val nll=110.99057965959821\n",
            "saved!\n",
            "Epoch: 12, val nll=110.91952427455357\n",
            "saved!\n",
            "Epoch: 13, val nll=110.91508021763393\n",
            "saved!\n",
            "Epoch: 14, val nll=110.8308935546875\n",
            "saved!\n",
            "Epoch: 15, val nll=110.81971261160714\n",
            "saved!\n",
            "Epoch: 16, val nll=110.55872907366071\n",
            "saved!\n",
            "Epoch: 17, val nll=110.2794677734375\n",
            "saved!\n",
            "Epoch: 18, val nll=109.91343540736607\n",
            "saved!\n",
            "Epoch: 19, val nll=109.21138811383929\n",
            "saved!\n",
            "Epoch: 20, val nll=108.7858251953125\n",
            "saved!\n",
            "Epoch: 21, val nll=108.14697684151785\n",
            "saved!\n",
            "Epoch: 22, val nll=107.58140206473215\n",
            "saved!\n",
            "Epoch: 23, val nll=106.93747140066964\n",
            "saved!\n",
            "Epoch: 24, val nll=106.82478655133929\n",
            "saved!\n",
            "Epoch: 25, val nll=106.27150320870535\n",
            "saved!\n",
            "Epoch: 26, val nll=106.24565987723214\n",
            "saved!\n",
            "Epoch: 27, val nll=106.168720703125\n",
            "saved!\n",
            "Epoch: 28, val nll=105.71067940848214\n",
            "saved!\n",
            "Epoch: 29, val nll=105.89643973214285\n",
            "Epoch: 30, val nll=105.51462611607143\n",
            "saved!\n",
            "Epoch: 31, val nll=105.1707763671875\n",
            "saved!\n",
            "Epoch: 32, val nll=105.49829799107142\n",
            "Epoch: 33, val nll=105.15845424107142\n",
            "saved!\n",
            "Epoch: 34, val nll=104.78975864955358\n",
            "saved!\n",
            "Epoch: 35, val nll=104.93793666294643\n",
            "Epoch: 36, val nll=104.65259765625\n",
            "saved!\n",
            "Epoch: 37, val nll=104.180546875\n",
            "saved!\n",
            "Epoch: 38, val nll=104.18040666852679\n",
            "saved!\n",
            "Epoch: 39, val nll=103.748916015625\n",
            "saved!\n",
            "Epoch: 40, val nll=103.930478515625\n",
            "Epoch: 41, val nll=103.77370396205357\n",
            "Epoch: 42, val nll=103.52758370535715\n",
            "saved!\n",
            "Epoch: 43, val nll=103.60740373883928\n",
            "Epoch: 44, val nll=103.60633579799106\n",
            "Epoch: 45, val nll=103.40793247767857\n",
            "saved!\n",
            "Epoch: 46, val nll=103.51258858816965\n",
            "Epoch: 47, val nll=103.23789271763393\n",
            "saved!\n",
            "Epoch: 48, val nll=103.13053571428571\n",
            "saved!\n",
            "Epoch: 49, val nll=103.15977260044643\n",
            "Epoch: 50, val nll=103.03607421875\n",
            "saved!\n",
            "Epoch: 51, val nll=103.34701590401785\n",
            "Epoch: 52, val nll=102.96371372767857\n",
            "saved!\n",
            "Epoch: 53, val nll=102.50984235491072\n",
            "saved!\n",
            "Epoch: 54, val nll=102.548447265625\n",
            "Epoch: 55, val nll=102.26055873325893\n",
            "saved!\n",
            "Epoch: 56, val nll=102.41035435267857\n",
            "Epoch: 57, val nll=102.25820172991071\n",
            "saved!\n",
            "Epoch: 58, val nll=101.84837123325893\n",
            "saved!\n",
            "Epoch: 59, val nll=102.27072126116072\n",
            "Epoch: 60, val nll=102.36422991071429\n",
            "Epoch: 61, val nll=102.26073102678572\n",
            "Epoch: 62, val nll=101.74891880580357\n",
            "saved!\n",
            "Epoch: 63, val nll=101.85096400669643\n",
            "Epoch: 64, val nll=102.01187709263392\n",
            "Epoch: 65, val nll=101.6578515625\n",
            "saved!\n",
            "Epoch: 66, val nll=101.84122349330357\n",
            "Epoch: 67, val nll=102.01712193080357\n",
            "Epoch: 68, val nll=101.90710518973215\n",
            "Epoch: 69, val nll=101.77991350446429\n",
            "Epoch: 70, val nll=101.97217982700893\n",
            "Epoch: 71, val nll=101.75367954799107\n",
            "Epoch: 72, val nll=101.20503976004464\n",
            "saved!\n",
            "Epoch: 73, val nll=101.557900390625\n",
            "Epoch: 74, val nll=101.4512255859375\n",
            "Epoch: 75, val nll=101.89584193638393\n",
            "Epoch: 76, val nll=101.53841169084822\n",
            "Epoch: 77, val nll=101.64708635602679\n",
            "Epoch: 78, val nll=101.31287458147321\n",
            "Epoch: 79, val nll=101.51839076450892\n",
            "Epoch: 80, val nll=101.38497000558036\n",
            "Epoch: 81, val nll=101.20023018973214\n",
            "saved!\n",
            "Epoch: 82, val nll=101.24716448102679\n",
            "Epoch: 83, val nll=101.52480608258928\n",
            "Epoch: 84, val nll=101.15179827008929\n",
            "saved!\n",
            "Epoch: 85, val nll=101.323115234375\n",
            "Epoch: 86, val nll=100.87995535714286\n",
            "saved!\n",
            "Epoch: 87, val nll=101.28899623325893\n",
            "Epoch: 88, val nll=101.43138323102679\n",
            "Epoch: 89, val nll=101.29257184709822\n",
            "Epoch: 90, val nll=101.29626674107143\n",
            "Epoch: 91, val nll=101.27577915736607\n",
            "Epoch: 92, val nll=101.22692940848215\n",
            "Epoch: 93, val nll=101.09366838727678\n",
            "Epoch: 94, val nll=101.30258231026785\n",
            "Epoch: 95, val nll=101.07295758928572\n",
            "Epoch: 96, val nll=101.07960309709821\n",
            "Epoch: 97, val nll=101.25518415178571\n",
            "Epoch: 98, val nll=100.94275948660714\n",
            "Epoch: 99, val nll=101.21864467075893\n",
            "Epoch: 100, val nll=101.1428271484375\n",
            "Epoch: 101, val nll=101.48366629464286\n",
            "Epoch: 102, val nll=101.10760463169643\n",
            "Epoch: 103, val nll=101.44889369419643\n",
            "Epoch: 104, val nll=101.19704171316964\n",
            "Epoch: 105, val nll=101.08325892857142\n",
            "Epoch: 106, val nll=101.10878348214285\n",
            "Epoch: 107, val nll=101.25559361049108\n",
            "FINAL LOSS: nll=97.04140013282998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "--2023-12-20 14:01:38--  https://raw.githubusercontent.com/jmtomczak/intro_dgm/main/vaes/vae_example.ipynb\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20756 (20K) [text/plain]\n",
            "Saving to: vae_example.ipynb\n",
            "\n",
            "     0K .......... ..........                                 100% 12.8M=0.002s\n",
            "\n",
            "2023-12-20 14:01:39 (12.8 MB/s) - vae_example.ipynb saved [20756/20756]\n",
            "\n",
            "[NbConvertApp] Converting notebook vae_example.ipynb to python\n",
            "[NbConvertApp] Writing 13956 bytes to vae_example.py\n"
          ]
        }
      ]
    }
  ]
}