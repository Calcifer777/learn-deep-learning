# Basics

## Activation functions

Output layer:
- Sigmoid: binary output
- Softmax: multiclass output
- Linear: regression

Hidden layer:
- Tanh
- ReLu
- Leaky ReLu
- eLu
- softplus
- maxout

## Loss functions

### Regression

[Review](https://analyticsindiamag.com/loss-functions-in-deep-learning-an-overview/)

- MSE
- MSLE

### Binary

- Binary cross entropy
- Hinge: measures the difference in sign

### Multiclass

- Categorical cross entropy
- Kullback Leibler Divergence Loss: measures the difference between distributions

## Glossary

- Epoch: one iteration through all the training data