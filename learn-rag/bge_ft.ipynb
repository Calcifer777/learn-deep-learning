{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM+BePeBkmJPCORZ5RMTmNl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Calcifer777/learn-deep-learning/blob/main/learn-rag/bge_ft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resources\n",
        "\n",
        "- Datasets: https://github.com/kongds/LightXML"
      ],
      "metadata": {
        "id": "V9uoD3FUkLWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "pip uninstall -y transformers # needed for working in colab\n",
        "pip install transformers flagembedding faiss-gpu  # or faiss-cpu, can't have both"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzxFLADvnv2C",
        "outputId": "ef4de08e-a88e-4b8c-941f-08efa46e0641"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.35.2\n",
            "Uninstalling transformers-4.35.2:\n",
            "  Successfully uninstalled transformers-4.35.2\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.4/8.4 MB 68.9 MB/s eta 0:00:00\n",
            "Collecting flagembedding\n",
            "  Downloading FlagEmbedding-1.2.5.tar.gz (37 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from flagembedding) (2.1.0+cu121)\n",
            "Collecting datasets (from flagembedding)\n",
            "  Downloading datasets-2.17.1-py3-none-any.whl (536 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.7/536.7 kB 52.9 MB/s eta 0:00:00\n",
            "Collecting accelerate>=0.20.1 (from flagembedding)\n",
            "  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 280.0/280.0 kB 38.5 MB/s eta 0:00:00\n",
            "Collecting sentence_transformers (from flagembedding)\n",
            "  Downloading sentence_transformers-2.3.1-py3-none-any.whl (132 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.8/132.8 kB 20.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.1->flagembedding) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->flagembedding) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->flagembedding) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->flagembedding) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->flagembedding) (2.1.0)\n",
            "Collecting pyarrow>=12.0.0 (from datasets->flagembedding)\n",
            "  Downloading pyarrow-15.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 38.3/38.3 MB 15.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->flagembedding) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->flagembedding)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 116.3/116.3 kB 7.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->flagembedding) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->flagembedding) (3.4.1)\n",
            "Collecting multiprocess (from datasets->flagembedding)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.8/134.8 kB 18.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->flagembedding) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers->flagembedding) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers->flagembedding) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers->flagembedding) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence_transformers->flagembedding) (0.1.99)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers->flagembedding) (9.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->flagembedding) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->flagembedding) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->flagembedding) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->flagembedding) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->flagembedding) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->flagembedding) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->flagembedding) (2.1.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers->flagembedding) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers->flagembedding) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->flagembedding) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->flagembedding) (2023.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers->flagembedding) (3.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->flagembedding) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->flagembedding) (1.16.0)\n",
            "Building wheels for collected packages: flagembedding\n",
            "  Building wheel for flagembedding (setup.py): started\n",
            "  Building wheel for flagembedding (setup.py): finished with status 'done'\n",
            "  Created wheel for flagembedding: filename=FlagEmbedding-1.2.5-py3-none-any.whl size=43015 sha256=1e06015f7ce6733c3cdab2f468a63f9dc2ab1d06418c4a9db26ba80f6c08fe5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/b3/70/bb01bbe4d671974606861835ee82b86c0cf24c92cee749edd6\n",
            "Successfully built flagembedding\n",
            "Installing collected packages: pyarrow, dill, multiprocess, accelerate, transformers, datasets, sentence_transformers, flagembedding\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 10.0.1\n",
            "    Uninstalling pyarrow-10.0.1:\n",
            "      Successfully uninstalled pyarrow-10.0.1\n",
            "Successfully installed accelerate-0.27.2 datasets-2.17.1 dill-0.3.8 flagembedding-1.2.5 multiprocess-0.70.16 pyarrow-15.0.0 sentence_transformers-2.3.1 transformers-4.37.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping quaterion as it is not installed.\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 15.0.0 which is incompatible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters"
      ],
      "metadata": {
        "id": "wKhA3y3s4JZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"BAAI/bge-m3\"\n",
        "\n",
        "lowest_label = 54\n",
        "highest_label = 80\n",
        "max_neg_samples = 8"
      ],
      "metadata": {
        "id": "Ne4jmbnD4Ij8"
      },
      "execution_count": 308,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_url_tmpl = \" https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "datasets = {\n",
        "    \"amazon13k\": \"1VwHAbri6y6oh8lkpZ6sSY_b1FRNnCLFL\",  # alternative link, but only with label ids\n",
        "    \"amazon13k-full\": \"17rVRDarPwlMpb3l5zof9h34FlwbpTu4l\",\n",
        "}"
      ],
      "metadata": {
        "id": "IYdYle30BUIb"
      },
      "execution_count": 283,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Data"
      ],
      "metadata": {
        "id": "nPnl8rz0lzjc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 364,
      "metadata": {
        "id": "R985Xc1nfqb3"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from itertools import compress\n",
        "import random\n",
        "\n",
        "import gdown\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from FlagEmbedding  import BGEM3FlagModel, FlagModel\n",
        "\n",
        "import faiss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_name = \"amazon13k\"\n",
        "\n",
        "gdown.download(\n",
        "    google_url_tmpl.format(file_id=datasets[ds_name]),\n",
        "    f\"./datasets/{ds_name}/\",\n",
        ")"
      ],
      "metadata": {
        "id": "cVdXErx5ky_2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "2a29671d-ba57-45a4-dd0b-1d03b297c111"
      },
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original):  https://drive.google.com/uc?id=1VwHAbri6y6oh8lkpZ6sSY_b1FRNnCLFL\n",
            "From (redirected): https://drive.google.com/uc?id=1VwHAbri6y6oh8lkpZ6sSY_b1FRNnCLFL&confirm=t&uuid=d2e9453b-4ae7-4b80-a56d-dd791352b95b\n",
            "To: /content/datasets/amazon13k/AmazonCat-13K.tar.gz\n",
            "100%|██████████| 796M/796M [00:30<00:00, 25.9MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./datasets/amazon13k/AmazonCat-13K.tar.gz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_name = \"amazon13k-full\"\n",
        "\n",
        "gdown.download(\n",
        "    google_url_tmpl.format(file_id=datasets[ds_name]),\n",
        "    f\"./datasets/{ds_name}/\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "VzqwHw2nLs-j",
        "outputId": "ed0f6762-99ca-4b43-fc70-7d0485091e40"
      },
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original):  https://drive.google.com/uc?id=17rVRDarPwlMpb3l5zof9h34FlwbpTu4l\n",
            "From (redirected): https://drive.google.com/uc?id=17rVRDarPwlMpb3l5zof9h34FlwbpTu4l&confirm=t&uuid=f5e0687e-c5d3-4a30-8ef0-223a4930b9bb\n",
            "To: /content/datasets/amazon13k-full/AmazonCat-13K.raw.zip\n",
            "100%|██████████| 837M/837M [00:26<00:00, 31.2MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./datasets/amazon13k-full/AmazonCat-13K.raw.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "tar -xvf ./datasets/amazon13k/AmazonCat-13K.tar.gz -C ./datasets/amazon13k/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOqCn4L6Lqgs",
        "outputId": "b9eb6fc7-766b-4932-8b86-8622cf3b90f6"
      },
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AmazonCat-13K/train_raw_texts.txt\n",
            "AmazonCat-13K/test_raw_texts.txt\n",
            "AmazonCat-13K/train_labels.txt\n",
            "AmazonCat-13K/test_labels.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "head -5 ./datasets/amazon13k/AmazonCat-13K/train_raw_texts.txt\n",
        "head -5 ./datasets/amazon13k/AmazonCat-13K/train_labels.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fr8M5IBnmaAs",
        "outputId": "a810cbca-55f0-47d4-decc-83786fc843ca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Englanders on the Ohio Frontier: Migration and Settlement of Worthington, Ohio  /SEP/  Virginia E. McCormick served on the faculties of Pennsylvania State University, Iowa State University, and, most recently, Ohio State University. Her previous books include Farm Wife: A Self Portrait, 1886-1896 and Scioto Company Descendants: Genealogies of the Original Proprietors of Worthington, Ohio./i>Robert W. McCormick is professor emeritus and former assistant vice president for continuing education at Ohio State University. He is the author of Cockney: The Story of the 696th Armored Field Artillery Battalion in World War II.The McCormicks are coauthors of A. B. Graham: Country Schoolmaster and Extension Pioneer; Worthington Landmarks: Photo-Essays of Historic Worthington Properties; and Probing Worthington's Heritage.\n",
            "Le Petit Prince  /SEP/  Deluxe Double Disc Musical Spectacular that Comes with a 52 Page Booklet with Libretto and Notes.\n",
            "Nesco FS-120T American Harvest Food Slicer with Tilt Stand  /SEP/  Heavy duty construction plus innovative design equals outstanding product performance.  Made from sturdy, heavy duty cast aluminum housing combined with unique \"angle feed\" slicing surface makes slicing easier.  Easy to use thickness adjustment and quality, precision crafted Solingen stainless steel cutting blade helps produce perfect cuts. Dual switch safety feature ensures safety during operation. Unit disassembles easily and all removable parts are dishwasher safe, except control panel.  90 watt A/C motor.  Gray\n",
            "Hungarian Music  /SEP/  All products are BRAND NEW and factory sealed. Fast shipping and 100% Satisfaction Guaranteed.\n",
            "ESI 585K Deluxe Automotive DMM  /SEP/  The Deluxe Automotive DMM is a professional grade tool used for diagnosing electrical, computer and engine problems on any vehicle. Includes two sets of test leads, RPM pick-up, temperature probe, protective holster, 9 volt battery, instructions manual and carrying case. Inductive RPM pick-up features a five position, adjustable sensitivity switch.\n",
            "38 401 1471 5878 7766 11367 12583\r\n",
            "7961 13259\r\n",
            "4103 5939 6670 10916 11151\r\n",
            "7961 9237 13259\r\n",
            "719 3530 12181\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "unzip -j ./datasets/amazon13k-full/AmazonCat-13K.raw.zip \"AmazonCat-13K.raw/Yf.txt\" -d ./datasets/amazon13k/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBJfR0SJMGoO",
        "outputId": "ace2c622-ee05-4d3d-8f00-0a86a4368df1"
      },
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ./datasets/amazon13k-full/AmazonCat-13K.raw.zip\n",
            "  inflating: ./datasets/amazon13k/labels.txt/Yf.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filter only a subset of the dataset"
      ],
      "metadata": {
        "id": "GqdKD9Pv8w61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./datasets/amazon13k/Yf.txt\", \"r\", encoding=\"ISO-8859-1\") as fp:\n",
        "    lines = [l.strip() for l in fp.readlines()]\n",
        "\n",
        "id2labels = dict(zip(range(len(lines)), lines))"
      ],
      "metadata": {
        "id": "cSR_23ulMzW-"
      },
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(id2labels.items())[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LanMUhJ-NpFX",
        "outputId": "81d1d9b9-ca08-4971-d902-6e470460edb4"
      },
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, '& guitar'),\n",
              " (1, '& magic'),\n",
              " (2, '& nets'),\n",
              " (3, '& screens'),\n",
              " (4, '& sleeving')]"
            ]
          },
          "metadata": {},
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./datasets/amazon13k/AmazonCat-13K/train_labels.txt\", \"r\") as fp:\n",
        "    labels = [[int(x) for x in l.split()] for l in fp.readlines()]"
      ],
      "metadata": {
        "id": "AceVz2v26wZv"
      },
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selection_mask = [l[0] >= lowest_label and l[0] <= highest_label for l in labels]"
      ],
      "metadata": {
        "id": "tHnFwwgU6zO8"
      },
      "execution_count": 329,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_sel = [l[0] for l in compress(labels, selection_mask)]"
      ],
      "metadata": {
        "id": "bhWo4SQl7xpT"
      },
      "execution_count": 330,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(labels), len(labels_sel)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZ1ub8Az8Diy",
        "outputId": "b6945449-43ce-4f6a-94bc-05c83fa3678d"
      },
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1186239, 1732)"
            ]
          },
          "metadata": {},
          "execution_count": 333
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(labels_sel))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__K49m-xGs1x",
        "outputId": "aae5e5e7-c3cc-4600-c2a2-f54db6464286"
      },
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 334
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = labels_sel"
      ],
      "metadata": {
        "id": "0w6mHW7x8hyN"
      },
      "execution_count": 335,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = list()\n",
        "\n",
        "with open(\"./datasets/amazon13k/AmazonCat-13K/train_raw_texts.txt\", \"r\") as fp:\n",
        "    corpus = [l.strip() for l in fp.readlines()]\n",
        "\n",
        "corpus = list(compress(corpus, selection_mask))"
      ],
      "metadata": {
        "id": "-atjTD0e5K4R"
      },
      "execution_count": 336,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert len(labels) == len(corpus)"
      ],
      "metadata": {
        "id": "Bvx5I5-E7Z3s"
      },
      "execution_count": 337,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find Hard negatives"
      ],
      "metadata": {
        "id": "BRq2r0be2yaV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create corpus embeddings\n",
        "\n",
        "https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/baai_general_embedding/finetune/hn_mine.py"
      ],
      "metadata": {
        "id": "dH96x0WW86k9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_index(embeddings, use_gpu=False):\n",
        "    index = faiss.index_factory(embeddings.shape[1], \"Flat\")\n",
        "    embeddings = np.asarray(embeddings, dtype=np.float32)\n",
        "    if use_gpu:\n",
        "        co = faiss.GpuMultipleClonerOptions()\n",
        "        co.shard = True\n",
        "        co.useFloat16 = True\n",
        "        index = faiss.index_cpu_to_all_gpus(index, co=co)\n",
        "    index.add(embeddings)\n",
        "    return index"
      ],
      "metadata": {
        "id": "p6uo9gac448h"
      },
      "execution_count": 338,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_search(\n",
        "    index,\n",
        "    query,\n",
        "    topk: int = 200,\n",
        "    batch_size: int = 64,\n",
        "):\n",
        "    all_scores, all_inxs = [], []\n",
        "    for start_index in tqdm(range(0, len(query), batch_size), desc=\"Batches\", disable=len(query) < 256):\n",
        "        batch_query = query[start_index:start_index + batch_size]\n",
        "        batch_scores, batch_inxs = index.search(np.asarray(batch_query, dtype=np.float32), k=topk)\n",
        "        all_scores.extend(batch_scores.tolist())\n",
        "        all_inxs.extend(batch_inxs.tolist())\n",
        "    return all_scores, all_inxs"
      ],
      "metadata": {
        "id": "neJoK2YcBHYA"
      },
      "execution_count": 339,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FlagModel(model_name)"
      ],
      "metadata": {
        "id": "xt1FNx1B2xGn"
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = model.encode(corpus, batch_size=256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nmx0a6ag6Z-p",
        "outputId": "e4356439-5e18-4baa-d4f0-bc79b09ff0ed"
      },
      "execution_count": 340,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inference Embeddings: 100%|██████████| 7/7 [00:49<00:00,  7.03s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Index"
      ],
      "metadata": {
        "id": "IiJso5FMFuGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "faiss_index = create_index(embeddings)"
      ],
      "metadata": {
        "id": "4WltnvNj-6Tt"
      },
      "execution_count": 341,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_scores, q_indices = batch_search(faiss_index, embeddings, topk=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvgePrEXBC0a",
        "outputId": "74b4aa4c-6d0c-4583-c5e6-ce2909c2959e"
      },
      "execution_count": 360,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Batches: 100%|██████████| 28/28 [00:00<00:00, 50.52it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find negatives"
      ],
      "metadata": {
        "id": "Lq9oCXxkFwcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_negs = []\n",
        "\n",
        "for idx, (scores, indices) in enumerate(zip(q_scores, q_indices)):\n",
        "    ref_label = labels[idx]\n",
        "    neg_samples = []\n",
        "    for i in indices[1:]:\n",
        "        q_label = labels[i]\n",
        "        if q_label != ref_label:\n",
        "            neg_samples.append(i)\n",
        "    if len(neg_samples) > max_neg_samples:\n",
        "        neg_samples = random.sample(neg_samples, max_neg_samples)\n",
        "    all_negs.append(neg_samples)"
      ],
      "metadata": {
        "id": "NGmPofRmB86G"
      },
      "execution_count": 366,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_idx = 10\n",
        "\n",
        "print(\"Text:\", corpus[sample_idx])\n",
        "print(\"Label id:\", labels[sample_idx])\n",
        "print(\"Label:\", id2labels[labels[sample_idx]])\n",
        "print(\"\\nNegative samples\")\n",
        "for i in all_negs[sample_idx]:\n",
        "    print(\"\\tText:\", corpus[i])\n",
        "    print(\"\\tLabel:\", id2labels[labels[i]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kGKiVCJIWI-",
        "outputId": "298a0392-5b7b-4817-a780-3a17c73b8a65"
      },
      "execution_count": 367,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: SAIT 58167 Open Coat Aluminum Oxide 3-Inch x 21-Inch AO-X 120 Grit Sanding Belt, 10-Pack  /SEP/  United Abrasives, Inc./SAIT is a privatelyheld company that was established in 1970. Ourrelationship with SAIT, an Italian corporation foundedin 1953, began as we first manufactured coated abrasivebelts. By 1975 we had expanded our production to includebonded abrasives. The strong commitment between UnitedAbrasives, Inc. and SAIT continues today. We are well-known worldwide for quality, consistency, and the highest levels of service.  We are one of the largest and leading manufacturers of abrasiveproducts in the world. We only use premium materials. We demand consistent manufacturing operations and have the most rigorous quality control testing in the industry. United Abrasives manufactures a full line of bonded abrasives: grinding wheels, cuttingwheels, cup wheels, cones, plugs and a host of similar bonded products. We also manufacture a wide variety of sanding sheets, belts, rolls, flap discs, fiber and PSA discs. Plus,we offer a broad line of wire brushes, non-woven abrasives, precision diamond-cutTungsten Carbide Burs, diamond wheels, and a full line of accessories.\tAO-X: Aluminum oxide, open coat X weight cotton. For general purpose sanding and grinding where an open coat structure is needed. Best choice for soft woods, non-ferrous metals, aluminum, leather, rubber and other materials that have the tendency to load.\n",
            "Label id: 58\n",
            "Label: abrasive & finishing products\n",
            "\n",
            "Negative samples\n",
            "\tText: Invacare Supply Group Reusable Bedpads  /SEP/  Features 3 layers of protection including a 100% waterproof vinyl backed polyester backing that locks out moisture and staining, a poly/rayon super absorbent soaker layer that absorbs and traps fluids, and a quilted cotton blend dry-touch top layer that wicks moisture into the pad protecting the skin and maintaining skin wellness. Non-slip bottom layer keeps the pad flat and in place. Added protection at the center where needed most. Machine wash and dry with bleach. Latex-free and lead-free. One year warranty.\n",
            "\tLabel: absorbent pads\n",
            "\tText: Classic Tube K3 Orig St Coil/Ftg 25 Ft  /SEP/  Tubing: 3/16\" x .028 tube; 25' coils & 16 asstd steel ferrule nuts; Tinned Bundy Weld\n",
            "\tLabel: abs\n",
            "\tText: Prevail Bladder Control Pads, Maximum, 48 Pads (Pack of 4)  /SEP/  Discreet bladder protection. Odor control. Latex free. 1. Thinner dual layer pad same maximum absorbency, Neutralizes odor. 2. Quick Wick blue strip pulls moisture away from the skin. 3. Side shields for added protection. Made in USA.\n",
            "\tLabel: absorbent pads\n",
            "\tText: Visible Man: A True Story of Post-Racist America  /SEP/  Gilder's 1979 volume tells the story of Sam Brewer, a young African American man unjustly accused of rape. Though Brewer is the focus of the book, the circumstances paint a larger picture of the obstacles faced by countless black youths in America. In the 16 years that have passed since this book's debut, few of those impediments have been removed, making it as timely as ever.Copyright 1995 Reed Business Information, Inc.\t      --This text refers to an out of print or unavailable edition of this title.\n",
            "\tLabel: abuse\n",
            "\tText: Prevail Bladder Control Pads, Extra Absorbency  /SEP/  Discreet bladder protection. Odor control. Thinner dual layer pad same maximum absorbency, neutralizes odor. Quick wick blue strip pulls moisture away from the skin. Side shields for added protection. Made in USA.\n",
            "\tLabel: absorbent pads\n",
            "\tText: /SEP/  Specially designed super-absorbent center to keep you drier than any other thin pad. Gently raised center for a close, custom fit. Soft side shields curve the pad for a better fit and help stop leaks. Breathable outer cover to help you feel dry and comfortable. 8\" long.\n",
            "\tLabel: absorbent pads\n",
            "\tText: Kendall SureCare Disposable Underpad 23 x 36\"  /SEP/  Super-soft, white, non woven facing. Highly absorbent cellulose fiber. Embossed, polyethylene nonskid backing. Imprinted polybag. 23 x 36\n",
            "\tLabel: absorbent pads\n",
            "\tText: Motorcraft BRAB15 Rear Wheel AntiLock Brake System Sensor  /SEP/  Motorcraft Rear Wheel AntiLock Brake System Sensors are designed and tested to meet OE specifications for durability and reliability under extreme conditions. These are manufactured using high standards which ensure long lasting durability. They have high resistance and offer superior service life.\n",
            "\tLabel: abs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"hnn.jsonl\", \"w\") as fp:\n",
        "    for i, text in enumerate(corpus):\n",
        "        data = dict(\n",
        "            text=text,\n",
        "            neg=[corpus[neg_idx] for neg_idx in all_negs[i]],\n",
        "        )\n",
        "        fp.write(json.dumps(data, ensure_ascii=False)+\"\\n\")"
      ],
      "metadata": {
        "id": "aoZHQjOwF3PH"
      },
      "execution_count": 374,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "head -1 hnn.jsonl | python -m json.tool"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSN107GYQ-qL",
        "outputId": "f17a6ac3-4312-4697-bd14-9e1362d94276"
      },
      "execution_count": 379,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"text\": \"Dignity Extra Duty Pads Extra-Double Duty 30/Bag  /SEP/  Dignity Extra Duty Pads are for moderate to heavy protection. Best used with Dignity garment or regular pants. Double pad is made of fluff filling and a soft, non-woven covering. Pad can be cut for single use, or layered for triple protection. No moisture-proof backing or adhesive strip.\",\n",
            "    \"neg\": [\n",
            "        \"Eagle U778-1000 - 6 inch SUPER-TACK Yellow-Film Discs - Grit P1000 - (Job-Pak) - 5 Discs/Pack - 1 Pack  /SEP/  Long lasting high performance Yellow-Film discs cut extremely fast and uniform. Designed for use in topcoat sanding to remove excess orange peel, over-runs, and dust nibs. Can also be used for light scuff sanding before painting. SUPER-TACK system provides cooler sanding and the convenience of easy on and off from disc pad. Recommended using with Cushion Pad (Part no. 04631). SUPER-TACK= Velour backing\",\n",
            "        \"3M 81433 4-Inch x 24-Inch Purple Regalite Resin Bond 120 Grit Cloth Sanding Belt - 5 Pack  /SEP/  Whether you need to grind, blend, polish, sand, prep, cut, clean or repair surfaces, 3M is the source for surface conditioning, coated, bonded, and superabrasives for use in metal fabrication, precision castings, cylindrical grinding, furniture and custom wood, automotive manufacturing, maintenance and more.These P-graded 3M Regalite Construction Belts provide increased cut rate, more uniform finish and higher stock removal with less heat and loading for wood sanding.\\tHeavy duty purple sanding belts have resin over resin bonded Regalite ceramic mineral construction gives an aggressive initial cut, consistant cut rate, and a long life. Faster stock removal with less heat and loading. Better leveling with a more uniform finish. Extra heavy Y weight cloth resists tearing. Flush joined belt will run in both directions to increase belt life.\",\n",
            "        \"Grizzly G3866 1/4 Sanding Sheet A220 H&#38;L, 5 pc.  /SEP/  Ideal for hook and loop palm sanders, these felt backed aluminum oxide sanding sheets come in the most popular grits for fine finishing. Sanding sheets measure 4 1/2 x 5 1/2\",\n",
            "        \"Apple 85 Watt Portable Power Adapter with AC Extension wall cord for MacBook Pro  /SEP/  The 85 Watt Apple Portable Power Adapter features the MagSafe Connector, a magnetic DC connector that ensures your power cable will disconnect if it experiences undue strain and helps prevent fraying or weakening of the cables over time. In addition, the magnetic DC helps guide the plug into the system for a quick and secure connection. When the connection is secure, an LED located at the head of the DC connector will light. An amber light lets you know that your portable is charging, while a green light tells you that you have a full charge. An AC cord is provided with the adapter for maximum cord length, while the AC wall adapter gives users an even easier and more compact way to travel. Designed to be the perfect traveling companion, the adapter has a clever design which allows the DC cable to be wound neatly around itself for easy cable storage. This power adapter recharges the lithium polymer battery while the system is off, on, or in sleep mode. It also powers the system if you choose to operate without a battery. Connector for optional dock   Stereo Minijack   Hold Switch   Charge Time - about 3 hours (1.5 hour fast charge to 80% capacity)   Audio Support - AAC (16 to 320 Kbps) / Protected AAC (from iTunes Music Store) / MP3 (16 to 320 Kbps) / MP3 VBR / Audible (formats 2, 3, & 4) / Apple Lossless / WAV / AIFF   Photo Support - JPEG / BMP / GIF / TIFF / PSD (Mac only) / PNG   Sync & Charge via USB Cable   Adjust audiobook playback speed   Create multiple on-the-go playlists   Shuffle songs or albums   Repeat one or all   20 Equalizer settings   Backlight Timer   Display Contrast   Alarm - On / Off / Silent   Sleep Timer   Date & Time   Display time in menu bar   Color - Black   Supports - Windows 2000 with Service Pack 4 or later, Windows XP Home or Professional with Service Pack 2 or later, Mac OS X v10.3.4 or later   Unit Dimensions - 3.5 x 1.6 x 0.27   Unit Weight - 1.5 ounces\",\n",
            "        \"Raybestos BH38584 Professional Grade Brake Hydraulic Hose  /SEP/  Raybestos Brake Hose is designed to transfer the brake fluid from the master cylinder to the slave cylinder for braking. This hose meets federal standards to ensure performance and safety, while providing longer hose life. It utilizes premium fittings to ensure a good hydraulic seal.\",\n",
            "        \"3M SandBlaster Between Coats Sandpaper, 400-Grit, 9-Inch by 11-Inch  /SEP/  Ideal for sanding between coats for a perfect finish. Gold in color for easy identification, this high performance mineral coating stays sharper longer and gives a finer finish than conventional sandpaper.\",\n",
            "        \"Porter-Cable 714000805 4-Inch x 24-Inch 80 Grit Multi-Purpose Sanding Belts (5-Pack)  /SEP/  Porter-Cable 714000805 4-Inch x 24-Inch 80 Grit Multi-Purpose Sanding Belts - 5 Pack\",\n",
            "        \"Centric Parts 130.44908 Brake Master Cylinder  /SEP/  Premium Master Cylinder MASTER CYLINDER Reservoirs and caps included. Pressure tested for worry free performance. Wide application coverage.\"\n",
            "    ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "K28AIyR-qrDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "faiss.StandardGpuResources"
      ],
      "metadata": {
        "id": "aDWdJszeumJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "02NoEqUcumF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JazteZEkul_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ua6K_Ip1ne4L"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "rc3LtmDHoCnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AmazonDataset(Dataset):\n",
        "\n",
        "    def __init__(self, path_data: str, path_labels: str):\n",
        "        super().__init__()\n",
        "        with open(path_data, \"r\") as fp:\n",
        "            self.data = [l.strip() for l in fp.readlines()]\n",
        "        with open(path_labels, \"r\") as fp:\n",
        "            self.labels = [l.strip().split() for l in fp.readlines()]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index: int) -> SimilarityGroupSample:\n",
        "        item = self.data[index]\n",
        "        return SimilarityGroupSample(obj=item, group=self.labels[index][0])\n",
        "\n",
        "    @property\n",
        "    def num_labels(self):\n",
        "        return len(set(x for l in ds_train.labels for x in l))"
      ],
      "metadata": {
        "id": "7CKDuGd2umnJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train = AmazonDataset(\n",
        "    path_data=\"./datasets/amazon13k/AmazonCat-13K/train_raw_texts.txt\",\n",
        "    path_labels=\"./datasets/amazon13k/AmazonCat-13K/train_labels.txt\"\n",
        ")"
      ],
      "metadata": {
        "id": "KEW8o55QoIg9"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_valid = AmazonDataset(\n",
        "    path_data=\"./datasets/amazon13k/AmazonCat-13K/test_raw_texts.txt\",\n",
        "    path_labels=\"./datasets/amazon13k/AmazonCat-13K/test_labels.txt\"\n",
        ")"
      ],
      "metadata": {
        "id": "GeHFv_U2qyfU"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-pskbTFpvsG",
        "outputId": "26074e6c-1a2d-4648-fefe-b2e9a5440428"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimilarityGroupSample(obj=\"New Englanders on the Ohio Frontier: Migration and Settlement of Worthington, Ohio  /SEP/  Virginia E. McCormick served on the faculties of Pennsylvania State University, Iowa State University, and, most recently, Ohio State University. Her previous books include Farm Wife: A Self Portrait, 1886-1896 and Scioto Company Descendants: Genealogies of the Original Proprietors of Worthington, Ohio./i>Robert W. McCormick is professor emeritus and former assistant vice president for continuing education at Ohio State University. He is the author of Cockney: The Story of the 696th Armored Field Artillery Battalion in World War II.The McCormicks are coauthors of A. B. Graham: Country Schoolmaster and Extension Pioneer; Worthington Landmarks: Photo-Essays of Historic Worthington Properties; and Probing Worthington's Heritage.\", group='38')"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train.num_labels, ds_valid.num_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPs2fC0Up7Um",
        "outputId": "f30175a2-924e-4262-db9f-0aeed1d5a84d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13330, 13330)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(ds_train), len(ds_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h6d7szBqudS",
        "outputId": "4a0aca2f-b0b0-4fd9-c811-bbdbbe910b50"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1186239, 306782)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    }
  ]
}