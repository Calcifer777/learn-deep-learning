{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72c81ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a068c406",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021e48b2",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65596a9",
   "metadata": {},
   "source": [
    "## Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05ae650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.rand(3, 6)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a65a866",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in enumerate(dataset):\n",
    "  print(f\"row {i}: {row.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875862f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in enumerate(dataset.take(2)):\n",
    "  print(f\"row {i}: {row.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5009a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14560597",
   "metadata": {},
   "source": [
    "## From memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a6d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9534ef6d",
   "metadata": {},
   "source": [
    "Training and test sets are tuples where the first tuple element contains feature images and the second contains corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266db5a7-46d6-4fef-beae-ff14b7d3322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img, train_lbl = train\n",
    "test_img, test_lbl = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27d393c-f041-4cb8-9f3d-3033934661af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = train_img / 255.0\n",
    "test_image = test_img / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3005915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image.shape, train_lbl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c844ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image.shape, test_lbl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda3dcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_image[np.random.randint(0, 60000)], cmap=\"ocean\", interpolation='nearest')\n",
    "plt.axis(\"off\")\n",
    "plt.grid(visible=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd833596",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_image, train_lbl))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_image, test_lbl))\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2985c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train_ds.take(1).as_numpy_iterator().next()\n",
    "img.shape, label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeac4ca",
   "metadata": {},
   "source": [
    "The batch() method takes n examples from a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db5affc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch, label_batch = (\n",
    "  train_ds.batch(5).take(1)\n",
    "    .as_numpy_iterator().next()\n",
    ")\n",
    "img_batch.shape, label_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4daae7-5048-4498-8aca-0874a82838fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = ['T-shirt/top', 'Trouser', 'Pullover', \n",
    "                'Dress', 'Coat', 'Sandal', 'Shirt', \n",
    "                'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c944e5c2-c200-434d-849c-c5f115a0c08a",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6a4a1c-f2f9-4018-8e4e-656cf01afa2c",
   "metadata": {},
   "source": [
    "- **Prefetching**: overlaps data preprocessing and model execution while training\n",
    "- **Caching**: keeps data in memory after it is loaded off disk during the first epoch\n",
    "- **Shuffling**\n",
    "- **Batching**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ca4156-5994-4092-b8b2-44d0df4cd967",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHUFFLE_SIZE = 5000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_ds_batched = (\n",
    "    train_ds\n",
    "    .shuffle(SHUFFLE_SIZE)\n",
    "    .batch(BATCH_SIZE) \n",
    ")\n",
    "train_ds_fmt = (\n",
    "    train_ds_batched\n",
    "    .cache()\n",
    "    .prefetch(1)  # works at the batch level\n",
    ")\n",
    "test_ds_batched = (\n",
    "    test_ds\n",
    "    .batch(BATCH_SIZE) \n",
    ")\n",
    "test_ds_fmt = (\n",
    "    test_ds_batched\n",
    "    .cache()\n",
    "    .prefetch(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d60ac3f-bde4-4b6b-93ed-79bee3e87f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, lbls = train_ds_fmt.take(1).as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf15ba74-9324-428d-8f83-8ea6d3ccab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d098c7-4db9-407f-a6d5-cbbf1e6bc130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2212767-9b06-4d09-bd34-9e0e2fe2bfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f302f59e-7e26-47b0-95ee-18c4c2e42071",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_params = (28*28)                     # 784  \n",
    "dense_1_params = (flatten_params + 1) * 128  # 100480\n",
    "dense_2_params = (128 + 1) * 10              # 1290"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7e0e55-1154-44b7-bc60-51bbbbfdac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = train_ds.take(1).element_spec[0].shape\n",
    "img_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cec3196-05e3-4c6a-abee-f3496fe997a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  Flatten(input_shape=img_shape),\n",
    "  Dense(128, activation='relu'),\n",
    "  Dropout(0.4),\n",
    "  Dense(10, activation=None)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967772af-09da-43b2-aa9e-60277c5a5e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a30671-8f66-43bd-bfc9-c6729f8dc089",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds_fmt,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    "    validation_data=test_ds_fmt,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-deep-learning",
   "language": "python",
   "name": "learn-deep-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
